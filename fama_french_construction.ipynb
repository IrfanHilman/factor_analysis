{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e0f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48b38ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/irfanhilman/factor_analysis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712f9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_1 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 1.csv')\n",
    "database_2 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 2.csv')\n",
    "database_3 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 3.csv')\n",
    "database_4 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 4.csv')\n",
    "database_5 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 5.csv')\n",
    "database_6 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 6.csv')\n",
    "database_7 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 7.csv')\n",
    "database_8 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 8.csv')\n",
    "database_9 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 9.csv')\n",
    "database_10 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 10.csv')\n",
    "database_11 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 11.csv')\n",
    "database_12 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 12.csv')\n",
    "database_13 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 13.csv')\n",
    "database_14 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 14.csv')\n",
    "database_15 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 15.csv')\n",
    "database_16 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 16.csv')\n",
    "database_17 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 17.csv')\n",
    "database_18 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 18.csv')\n",
    "database_19 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 19.csv')\n",
    "database_20 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 20.csv')\n",
    "database_21 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 21.csv')\n",
    "database_22 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 22.csv')\n",
    "database_23 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 23.csv')\n",
    "database_24 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 24.csv')\n",
    "database_25 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 25.csv')\n",
    "database_26 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 26.csv')\n",
    "database_27 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 27.csv')\n",
    "database_28 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 28.csv')\n",
    "database_29 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 29.csv')\n",
    "database_30 = pd.read_csv('/Users/irfanhilman/quanti-trading-plan/data/database_daily_update/Database Part 30.csv')\n",
    "database = pd.concat([database_1,database_2,database_3,database_4,database_5,database_6,database_7,database_8,database_9,database_10,\n",
    "                      database_11,database_12,database_13,database_14,database_15,database_16,database_17,database_18,database_19,database_20,\n",
    "                      database_21,database_22,database_23,database_24,database_25,database_26,database_27,database_28,database_29,database_30])\n",
    "database = database.drop(columns='Unnamed: 0')\n",
    "#Substitusi nilai Open, High, Low Price yg 0 dengan Close Price\n",
    "database['Open Price'] = np.where(database['Open Price'].eq(0),database['Close Price'],database['Open Price'])\n",
    "database['High Price'] = np.where(database['High Price'].eq(0),database['Close Price'],database['High Price'])\n",
    "database['Low Price'] = np.where(database['Low Price'].eq(0),database['Close Price'],database['Low Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f94a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASIC PARAMETER\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2025-03-21' #'2025-03-21'\n",
    "hold_period = 21 #in days\n",
    "factor = ['Sales/Market','Momentum 252 Days Skip 0 Days' ] #other than Size (Market Cap)\n",
    "weighting = 'Value-Weight' #'Value-Weight','Equal-Weight'\n",
    "hold_type = 'Periodic' #'Periodic' or 'First-Day in Month'\n",
    "#partition = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4805914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCREENING PARAMETER\n",
    "screening_param = ['Market Cap','Total Ekuitas','Close Price','Median Transaction Value 1 Month'] #Params\n",
    "screening_sign = ['Above','Above','Above','Above'] #Above, Below, Not Equal, or Between. If Between, assign a list in screening_val: screening_val = [[min,max]]\n",
    "screening_val = [100_000_000_000,0,50,100_000_000] #Numeric variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b11c99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Stocks\n",
    "drop_list = ['excl', 'ihsg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6127ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_stocks(data,drop_list):\n",
    "    for r in drop_list:\n",
    "        data= data[data['Kode']!=r]\n",
    "    else: pass\n",
    "    return data\n",
    "\n",
    "def screening_stocks(data,screening_params,screening_signs,screening_vals):\n",
    "    if len(screening_params) == len(screening_signs) == len(screening_vals):\n",
    "        for ens,j in enumerate(screening_params):  #Initial Screening\n",
    "            if screening_signs[ens] == 'Above':\n",
    "                data = data[data[j]>screening_vals[ens]]\n",
    "            elif screening_signs[ens] == 'Below':\n",
    "                data = data[data[j]<screening_vals[ens]]\n",
    "            elif screening_signs[ens] == 'Not Equal':\n",
    "                data = data[data[j]!=screening_vals[ens]]\n",
    "            elif screening_signs[ens] == 'Between':\n",
    "                data = data[(data[j]>=screening_vals[ens][0])&(data[j]<=screening_vals[ens][1])]\n",
    "            else:\n",
    "                raise TypeError('screening_sign wrong. Select either Above or Below')\n",
    "    else:\n",
    "        raise Exception('Number of elements in screening parameter list are different')\n",
    "    return data\n",
    "\n",
    "def apply_weighting(data,weighting):\n",
    "        data = data.dropna(subset='Market Cap')\n",
    "        if weighting=='Equal-Weight':\n",
    "            data['Weight'] = 1/len(data)\n",
    "        elif weighting=='Value-Weight':\n",
    "            data['Weight'] = data['Market Cap']/data['Market Cap'].sum()\n",
    "        else:\n",
    "            raise TypeError('weighting wrong. See notes in the parameter setting section')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18bb71",
   "metadata": {},
   "source": [
    "Check buy_date_list dan sell_date_list beda length, harusnya sell_date_list bisa tambah 1 element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ac237a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_date_list = list(database['Date'].sort_values().unique())          \n",
    "if hold_type =='Periodic': \n",
    "    selected_date_list = database_date_list[::hold_period+1]\n",
    "elif hold_type =='First-Day in Month':\n",
    "    selected_date_list = []\n",
    "    database['Year'] = database['Date'].str[:4].astype('int')\n",
    "    database['Month'] = database['Date'].str[5:7].astype('int')\n",
    "    for i in database['Year'].unique():\n",
    "        database_i = database[database['Year']==i]\n",
    "        for j in database_i['Month'].unique():\n",
    "            database_j = database_i[database_i['Month']==j]\n",
    "            database_j = database_j.sort_values(by='Date')\n",
    "            date_list_j = list(database_j['Date'].unique())\n",
    "            first_day = date_list_j[0]\n",
    "            selected_date_list.append(first_day)\n",
    "    database = database.drop(columns=['Year','Month'])\n",
    "else:\n",
    "    raise TypeError('hold_type wrong. Select \"Periodic\" or \"First-Day in Month\"')\n",
    "buy_date_list = [d for d in selected_date_list if d >= start_date and d <= end_date]\n",
    "sell_date_list = []\n",
    "for i in buy_date_list[1:]:\n",
    "    sell_date_i = database_date_list.index(i)-1\n",
    "    sell_date = database_date_list[sell_date_i]\n",
    "    sell_date_list.append(sell_date)\n",
    "param_date_index = [(database_date_list.index(p)-1) for p in buy_date_list]\n",
    "param_date_list = [database_date_list[p] for p in param_date_index]\n",
    "size_param = ['Date','Kode','Market Cap']\n",
    "database_part = database.copy()\n",
    "database_part = database_part[database_part['Date'].isin(param_date_list)]\n",
    "database_part = database_part.dropna(subset=['Date','Kode','Market Cap'])\n",
    "database_part = database_part.dropna(subset=factor)\n",
    "database_part = drop_stocks(data=database_part,drop_list=drop_list)\n",
    "database_part = screening_stocks(data=database_part,screening_params=screening_param,screening_signs=screening_sign,screening_vals=screening_val)\n",
    "database_part_size = database_part[size_param]\n",
    "df_small_list = []\n",
    "df_big_list = []\n",
    "for i in list(database_part_size['Date'].sort_values().unique()):\n",
    "    database_part_size_i = database_part_size[database_part_size['Date']==i]\n",
    "    database_part_size_i = database_part_size_i.sort_values(by='Market Cap')\n",
    "    df_small_i = database_part_size_i[database_part_size_i['Market Cap']<database_part_size_i['Market Cap'].median()]\n",
    "    df_big_i = database_part_size_i[database_part_size_i['Market Cap']>=database_part_size_i['Market Cap'].median()]\n",
    "    df_small_list.append(df_small_i)\n",
    "    df_big_list.append(df_big_i)\n",
    "df_small = pd.concat(df_small_list)\n",
    "df_big = pd.concat(df_big_list)\n",
    "df_factor_top_dic = {}\n",
    "df_factor_medium_dic = {}\n",
    "df_factor_bottom_dic = {}\n",
    "for f in factor:\n",
    "    df_factor_top_dic[f\"Top {f}\"] = []\n",
    "    df_factor_medium_dic[f\"Medium {f}\"] = []\n",
    "    df_factor_bottom_dic[f\"Bottom {f}\"] = []\n",
    "for f in factor:\n",
    "    for i in list(database_part['Date'].sort_values().unique()):\n",
    "        database_part_i = database_part[database_part['Date']==i]\n",
    "        database_part_factor_i = database_part_i[['Date','Kode','Market Cap',f]]\n",
    "        database_part_factor_i = database_part_factor_i.sort_values(by=f)\n",
    "        database_part_factor_i_top =database_part_factor_i[database_part_factor_i[f]>database_part_factor_i[f].quantile(0.7)]\n",
    "        database_part_factor_i_medium =database_part_factor_i[(database_part_factor_i[f]>=database_part_factor_i[f].quantile(0.3))&(database_part_factor_i[f]<=database_part_factor_i[f].quantile(0.7))]\n",
    "        database_part_factor_i_bottom =database_part_factor_i[database_part_factor_i[f]<database_part_factor_i[f].quantile(0.3)]\n",
    "        df_factor_top_dic[f\"Top {f}\"].append(database_part_factor_i_top)\n",
    "        df_factor_medium_dic[f\"Medium {f}\"].append(database_part_factor_i_medium)\n",
    "        df_factor_bottom_dic[f\"Bottom {f}\"].append(database_part_factor_i_bottom)\n",
    "for f in factor:\n",
    "    df_factor_top = pd.concat(df_factor_top_dic[f\"Top {f}\"])\n",
    "    df_factor_top = df_factor_top.reset_index(drop=True)\n",
    "    df_factor_top_dic[f\"Top {f}\"] = df_factor_top\n",
    "    df_factor_medium = pd.concat(df_factor_medium_dic[f\"Medium {f}\"])\n",
    "    df_factor_medium = df_factor_medium.reset_index(drop=True)\n",
    "    df_factor_medium_dic[f\"Medium {f}\"] = df_factor_medium\n",
    "    df_factor_bottom = pd.concat(df_factor_bottom_dic[f\"Bottom {f}\"])\n",
    "    df_factor_bottom = df_factor_bottom.reset_index(drop=True)\n",
    "    df_factor_bottom_dic[f\"Bottom {f}\"] = df_factor_bottom\n",
    "\n",
    "#Sorting portfolio and Apply weighting\n",
    "reb_comp_dic = {}\n",
    "#for f in factor:\n",
    "#    for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "#        reb_comp_dic[f\"{n}{f}\"] = []\n",
    "for f in factor:\n",
    "    top_small_list = []\n",
    "    medium_small_list = []\n",
    "    bottom_small_list = []\n",
    "    top_big_list = []\n",
    "    medium_big_list = []\n",
    "    bottom_big_list = []\n",
    "    for en,i in enumerate(param_date_list[:-1]):\n",
    "        stock_top = df_factor_top_dic[f\"Top {f}\"][['Date','Kode','Market Cap']]\n",
    "        stock_top_i = stock_top[stock_top['Date']==i]\n",
    "        stock_medium = df_factor_medium_dic[f\"Medium {f}\"][['Date','Kode','Market Cap']]\n",
    "        stock_medium_i = stock_medium[stock_medium['Date']==i]\n",
    "        stock_bottom = df_factor_bottom_dic[f\"Bottom {f}\"][['Date','Kode','Market Cap']]\n",
    "        stock_bottom_i = stock_bottom[stock_bottom['Date']==i]\n",
    "        stock_small = df_small[['Date','Kode','Market Cap']]\n",
    "        stock_small_i = stock_small[stock_small['Date']==i]\n",
    "        stock_big = df_big[['Date','Kode','Market Cap']]\n",
    "        stock_big_i = stock_big[stock_big['Date']==i]\n",
    "        stock_top_small = pd.merge(stock_top_i,stock_small_i,how='inner')\n",
    "        stock_medium_small = pd.merge(stock_medium_i,stock_small_i,how='inner')\n",
    "        stock_bottom_small = pd.merge(stock_bottom_i,stock_small_i,how='inner')\n",
    "        stock_top_big = pd.merge(stock_top_i,stock_big_i,how='inner')\n",
    "        stock_medium_big = pd.merge(stock_medium_i,stock_big_i,how='inner')\n",
    "        stock_bottom_big = pd.merge(stock_bottom_i,stock_big_i,how='inner')\n",
    "        stock_top_small = apply_weighting(data=stock_top_small,weighting=weighting)\n",
    "        stock_medium_small = apply_weighting(data=stock_medium_small,weighting=weighting)\n",
    "        stock_bottom_small = apply_weighting(data=stock_bottom_small,weighting=weighting)\n",
    "        stock_top_big = apply_weighting(data=stock_top_big,weighting=weighting)\n",
    "        stock_medium_big = apply_weighting(data=stock_medium_big,weighting=weighting)\n",
    "        stock_bottom_big = apply_weighting(data=stock_bottom_big,weighting=weighting)\n",
    "        stock_top_small['From'] = buy_date_list[:-1][en]\n",
    "        stock_medium_small['From'] = buy_date_list[:-1][en]\n",
    "        stock_bottom_small['From'] = buy_date_list[:-1][en]\n",
    "        stock_top_big['From'] = buy_date_list[:-1][en]\n",
    "        stock_medium_big['From'] = buy_date_list[:-1][en]\n",
    "        stock_bottom_big['From'] = buy_date_list[:-1][en]\n",
    "        stock_top_small['To'] = sell_date_list[en]\n",
    "        stock_medium_small['To'] = sell_date_list[en]\n",
    "        stock_bottom_small['To'] = sell_date_list[en]\n",
    "        stock_top_big['To'] = sell_date_list[en]\n",
    "        stock_medium_big['To'] = sell_date_list[en]\n",
    "        stock_bottom_big['To'] = sell_date_list[en]\n",
    "        stock_top_small['Number'] = en+1\n",
    "        stock_medium_small['Number'] = en+1\n",
    "        stock_bottom_small['Number'] = en+1\n",
    "        stock_top_big['Number'] = en+1\n",
    "        stock_medium_big['Number'] = en+1\n",
    "        stock_bottom_big['Number'] = en+1\n",
    "        top_small_list.append(stock_top_small)\n",
    "        medium_small_list.append(stock_medium_small)\n",
    "        bottom_small_list.append(stock_bottom_small)\n",
    "        top_big_list.append(stock_top_big)\n",
    "        medium_big_list.append(stock_medium_big)\n",
    "        bottom_big_list.append(stock_bottom_big)\n",
    "    for l in [top_small_list,medium_small_list,bottom_small_list,top_big_list,medium_big_list,bottom_big_list]:\n",
    "        for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "            reb_comp_dic[f\"{n}{f}\"] = pd.concat(l).reset_index(drop=True)\n",
    "            reb_comp_dic[f\"{n}{f}\"] = reb_comp_dic[f\"{n}{f}\"][['Kode','Weight','From','To','Number']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0cbf2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_sell_date_list = buy_date_list + sell_date_list\n",
    "database_price = database[['Kode','Date','Open Price','High Price','Low Price','Close Price']]\n",
    "database_price = database_price[database_price['Date'].isin(buy_sell_date_list)]\n",
    "database_price['Kode + Date'] = database_price['Kode'].astype('str') + ' ' + database_price['Date'].astype('str')\n",
    "reb_comp_act_dic = {}\n",
    "for f in factor:\n",
    "    for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "        reb_comp_act_dic[f\"{n}{f}\"] = []\n",
    "for f in factor:\n",
    "    for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "        reb_comp = reb_comp_dic[f'{n}{f}']\n",
    "        start_date = reb_comp['From'].sort_values().astype('str').values[0]\n",
    "        end_date = reb_comp['To'].sort_values().astype('str').values[-1]\n",
    "        for i in list(reb_comp['Number'].sort_values().unique()):\n",
    "            reb_comp_i = reb_comp[reb_comp['Number']==i].reset_index(drop=True)\n",
    "            stock_list_i = list(reb_comp_i['Kode'])\n",
    "            if len(stock_list_i) > len(set(stock_list_i)):\n",
    "                print('Stock list is not unique')\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "            from_date = reb_comp_i['From'].astype('str').unique()[0]\n",
    "            reb_comp_act_i = pd.DataFrame({'Kode':stock_list_i})\n",
    "            reb_comp_act_i['Date'] = from_date \n",
    "            reb_comp_act_i['Kode + Date'] = reb_comp_act_i['Kode'].astype('str') + ' ' + reb_comp_act_i['Date'].astype('str')\n",
    "            reb_comp_act_i = reb_comp_act_i.merge(database_price.drop(columns=['Kode','Date']),how='left',on='Kode + Date')\n",
    "            reb_comp_act_i = reb_comp_act_i.drop(columns='Kode + Date')\n",
    "            reb_comp_act_i['Action'] = 'BUY'\n",
    "            reb_comp_act_i = reb_comp_act_i.sort_values(by='Kode').reset_index(drop=True)\n",
    "            reb_comp_act_dic[f\"{n}{f}\"].append(reb_comp_act_i)\n",
    "            to_date = reb_comp_i['To'].astype('str').unique()[0]\n",
    "            reb_comp_act_i = pd.DataFrame({'Kode':stock_list_i})\n",
    "            reb_comp_act_i['Date'] = to_date \n",
    "            reb_comp_act_i['Kode + Date'] = reb_comp_act_i['Kode'].astype('str') + ' ' + reb_comp_act_i['Date'].astype('str')\n",
    "            reb_comp_act_i = reb_comp_act_i.merge(database_price.drop(columns=['Kode','Date']),how='left',on='Kode + Date')\n",
    "            reb_comp_act_i = reb_comp_act_i.drop(columns='Kode + Date')\n",
    "            reb_comp_act_i['Action'] = 'SELL'\n",
    "            reb_comp_act_i = reb_comp_act_i.sort_values(by='Kode').reset_index(drop=True)\n",
    "            reb_comp_act_dic[f\"{n}{f}\"].append(reb_comp_act_i)\n",
    "for f in factor:\n",
    "    for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "        reb_comp_act_dic[f\"{n}{f}\"] = pd.concat(reb_comp_act_dic[f\"{n}{f}\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_dic = {}\n",
    "for f in factor:\n",
    "    for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "        transaction_dic[f\"{n}{f}\"] = []\n",
    "for f in factor:\n",
    "    for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "        reb_comp_act = reb_comp_act_dic[f\"{n}{f}\"]\n",
    "        reb_comp = reb_comp_dic[f'{n}{f}']\n",
    "        day_number = 0\n",
    "        reb_comp_act_full_day_list = []\n",
    "        for i in list(reb_comp_act['Date'].sort_values().unique()):\n",
    "            reb_comp_act_i = reb_comp_act[reb_comp_act['Date']==i]\n",
    "            reb_comp_act_i['Day Number'] = day_number\n",
    "            reb_comp_i = reb_comp[reb_comp['From']==i]\n",
    "            reb_comp_i = reb_comp_i.rename(columns={'From':'Date'})\n",
    "            reb_comp_i['Kode + Date'] = reb_comp_i['Kode'].astype('str') + ' ' + reb_comp_i['Date'].astype('str') \n",
    "            reb_comp_act_s_list = []\n",
    "            reb_comp_act_s_buy_list = []\n",
    "            for s in list(reb_comp_act_i['Kode'].sort_values()):\n",
    "                reb_comp_act_s = reb_comp_act_i[reb_comp_act_i['Kode']==s]\n",
    "                reb_comp_act_s['Initial Capital'] = 1_000_000_000\n",
    "                reb_comp_act_s['Reference Price'] = reb_comp_act_s['Close Price']\n",
    "                reb_comp_act_s['Price/Lot'] = reb_comp_act_s['Reference Price'].astype('float64')*100\n",
    "                reb_comp_act_s['Kode + Date'] = reb_comp_act_s['Kode'].astype('str') + ' ' + reb_comp_act_s['Date'].astype('str') \n",
    "                if reb_comp_act_s['Action'].values[0] == 'BUY':\n",
    "                    if day_number == 0:\n",
    "                        reb_comp_act_s['Reference Capital'] = 1_000_000_000\n",
    "                    else:\n",
    "                        reb_comp_act_s['Reference Capital'] = reb_comp_act_full_day['Total Capital'].iloc[-1]\n",
    "                    reb_comp_act_s = reb_comp_act_s.merge(reb_comp_i[['Kode + Date','Weight']],on='Kode + Date',how='left')\n",
    "                    reb_comp_act_s['Buy Price'] = reb_comp_act_s['Price/Lot']\n",
    "                    reb_comp_act_s['Sell Price'] = np.nan\n",
    "                    reb_comp_act_s['Buy Lot'] = reb_comp_act_s['Reference Capital']*reb_comp_act_s['Weight']/reb_comp_act_s['Buy Price']\n",
    "                    reb_comp_act_s['Sell Lot'] = np.nan\n",
    "                    reb_comp_act_s['Hold Lot'] = np.nan\n",
    "                    reb_comp_act_s['Capital Allocation'] = reb_comp_act_s['Reference Capital']*reb_comp_act_s['Weight']\n",
    "                    reb_comp_act_s['Invested'] = reb_comp_act_s['Buy Price']*reb_comp_act_s['Buy Lot']\n",
    "                    reb_comp_act_s['Sold'] = np.nan\n",
    "                    reb_comp_act_s['Market Value'] = reb_comp_act_s['Close Price']*reb_comp_act_s['Buy Lot']*100\n",
    "                    reb_comp_act_s['Potential P&L'] = reb_comp_act_s['Market Value'] - reb_comp_act_s['Invested']\n",
    "                    reb_comp_act_s['Realized P&L'] = np.nan\n",
    "                    reb_comp_act_s['Cash'] = reb_comp_act_s['Capital Allocation'] - reb_comp_act_s['Invested']\n",
    "                    reb_comp_act_s['ROI'] = np.nan\n",
    "                    reb_comp_act_s_buy_list.append(reb_comp_act_s)\n",
    "                elif reb_comp_act_s['Action'].values[0] == 'SELL':\n",
    "                    reb_comp_act_full_day_s = reb_comp_act_full_day[reb_comp_act_full_day['Kode']==s]\n",
    "                    reb_comp_act_s['Reference Capital'] = reb_comp_act_full_day['Total Market Value'].iloc[-1]\n",
    "                    reb_comp_act_s['Reference Price'] = reb_comp_act_s['Close Price']\n",
    "                    reb_comp_act_s['Weight'] = 0\n",
    "                    reb_comp_act_s['Buy Price'] = np.nan\n",
    "                    reb_comp_act_s['Sell Price'] = reb_comp_act_s['Price/Lot']\n",
    "                    reb_comp_act_s = reb_comp_act_s.merge(reb_comp_act_buy[['Kode','Buy Lot']],on='Kode',how='left')\n",
    "                    reb_comp_act_s = reb_comp_act_s.rename(columns={'Buy Lot':'Sell Lot'})\n",
    "                    reb_comp_act_s['Buy Lot'] = np.nan\n",
    "                    reb_comp_act_s['Hold Lot'] = np.nan\n",
    "                    reb_comp_act_s['Capital Allocation'] = np.nan\n",
    "                    reb_comp_act_s = reb_comp_act_s.merge(reb_comp_act_full_day_s[['Kode','Invested']],on='Kode',how='left')\n",
    "                    reb_comp_act_s['Sold'] = reb_comp_act_s['Sell Price']*reb_comp_act_s['Sell Lot']\n",
    "                    reb_comp_act_s['Market Value'] = np.nan\n",
    "                    reb_comp_act_s['Potential P&L'] = np.nan\n",
    "                    reb_comp_act_s['Realized P&L'] = reb_comp_act_s['Sold']-reb_comp_act_s['Invested']\n",
    "                    reb_comp_act_s = reb_comp_act_s.merge(reb_comp_act_full_day_s[['Kode','Cash']],on='Kode',how='left')\n",
    "                    reb_comp_act_s['Cash'] = reb_comp_act_s['Cash'] + reb_comp_act_s['Sold']\n",
    "                    sold = reb_comp_act_s['Sold'].iloc[0]\n",
    "                    invested = reb_comp_act_buy[reb_comp_act_buy['Kode']==s]['Invested'].iloc[0]\n",
    "                    reb_comp_act_s['ROI'] = (sold-invested)/invested\n",
    "                else: pass\n",
    "                reb_comp_act_s_list.append(reb_comp_act_s)\n",
    "            reb_comp_act_full_day = pd.concat(reb_comp_act_s_list)\n",
    "            reb_comp_act_full_day['Total Invested'] = reb_comp_act_full_day['Invested'].sum()\n",
    "            reb_comp_act_full_day['Total Market Value'] = reb_comp_act_full_day['Market Value'].sum()\n",
    "            reb_comp_act_full_day['Total Potential P&L'] = reb_comp_act_full_day['Potential P&L'].sum()\n",
    "            reb_comp_act_full_day['Total Realized P&L'] = reb_comp_act_full_day['Realized P&L'].sum()\n",
    "            reb_comp_act_full_day['Total Cash'] = reb_comp_act_full_day['Cash'].sum() \n",
    "            reb_comp_act_full_day['Total Capital'] = reb_comp_act_full_day['Total Market Value'] + reb_comp_act_full_day['Total Cash']\n",
    "            reb_comp_act_full_day['Weight'] = reb_comp_act_full_day['Weight'].fillna(value=reb_comp_act_full_day['Market Value']/reb_comp_act_full_day['Total Market Value'])\n",
    "            day_number = day_number + 1\n",
    "            transaction_dic[f\"{n}{f}\"].append(reb_comp_act_full_day)\n",
    "            if len(reb_comp_act_s_buy_list)>0:\n",
    "                reb_comp_act_buy = pd.concat(reb_comp_act_s_buy_list)\n",
    "for f in factor:\n",
    "    for n in ['top_small_','medium_small_','bottom_small_','top_big_','medium_big_','bottom_big_']:\n",
    "        transaction_dic[f\"{n}{f}\"] = pd.concat(transaction_dic[f\"{n}{f}\"]).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
